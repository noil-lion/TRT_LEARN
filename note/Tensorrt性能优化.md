
# Tensorrt性能优化策略
1. Batching  
Batching是可以统一处理的输入的集合。批次中的每个实例都具有相同的形状，并以完全相同的方式流经网络。因此，每个实例都可以简单地并行计算。最重要的优化是使用批处理并行计算尽可能多的结果。

2. 使用批处理  
在创建网络时使用显式批处理模式，则批处理维度是张量维度的一部分，您可以通过添加__优化配置文件__来指定批处理大小和批处理大小的范围以优化引擎。可以运行多个构建操作来为不同的批量大小创建多个优化引擎，然后在运行时根据实际批量大小选择要使用的引擎。

3. CUDA stream  
用到CUDA的程序一般需要处理海量的数据，内存带宽经常会成为主要的瓶颈。在Stream的帮助下，CUDA程序可以有效地将内存读取和数值运算并行，从而提升数据的吞吐量。  
异步且基于stream的kernel执行和数据传输能够实现以下几种类型的并行：
* Host运算操作和device运算操作并行
* Host运算操作和host到device的数据传输并行
* Host到device的数据传输和device运算操作并行
* Device内的运算并行]

如果不做特别处理，那么CUDA会默认只使用一个Stream（Default Stream）将输入数据从host转移到device->在device上执行kernel->将结果从device上转移回host,NVIDIA家的GPU有一下很不错的技能（不知道是不是独有）：数据拷贝和数值计算可以同时进行。两个方向的拷贝可以同时进行（GPU到CPU，和CPU到GPU）。Stream正是帮助我们实现以上两个并行的重要工具。  

Stream实现以上并行操作的基本概念是将数据拆分称许多块，每一块交给一个Stream来处理。  
* 将属于该Stream的数据从CPU内存转移到GPU内存
* GPU进行运算并将结果保存在GPU内存
* 将该Stream的结果从GPU内存拷贝到CPU内存 

__使用多个Stream令数据传输和计算并行，可比只用Default Stream增加相当多的吞吐量。在需要处理海量数据，Stream是一个十分重要的工具。__

在Tensorrt中针对cuda流的优化支持在两方面  
1. 使用流式传输

2. 多流并发




