# Tensorrt关键概念
## API
python API 和C++ API
## 编程模型
1. 构造阶段（模型定义和优化）
2. 运行时阶段（推理）
### 基本流程
* 创建网络定义。
* 指定构建器的配置。
* 调用构建器来创建引擎。


* 反序列化构造好的引擎的.plan。
* 从引擎创建执行上下文。
* 填充输入缓冲区以进行推理。
* 调用入队（）或者执行（）在执行上下文上运行推理。

## 插件
支持一下trt本身不支持的操作的实现。[插件库](https://github.com/NVIDIA/TensorRT/tree/main/plugin)

## 精度控制
默认在CUDA内核中执行浮点计算是为FP32数据类型，可通过配置BuilderFlag 选项来指示计算精度，降低计算精度值FP16可以提高计算速度，对于对于输入动态范围约为 1 的正则化模型计算。